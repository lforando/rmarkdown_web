---
title: "Blog Post #2 - Bring Back the Bodies"
---
<p>&nbsp;</p>

### **No Data, No Problem?**
##### *Missing data doesn't always indicate that there isn't a problem, it just means we are going about it the wrong way.*

 ![](https://media.istockphoto.com/vectors/black-pregnant-woman-with-nature-and-leaves-background-concept-vector-vector-id1171915511?k=6&m=1171915511&s=612x612&w=0&h=E2W2pwjc3buDMEPO9o88t3RgGLEm-5RM4p4X1Lse_gU=){size=25%}
 
|       Chapter 1, *Bring Back the Bodies*, was incredibly eye opening to me as well as disturbing. We all hear stories about women having complications during childbirth, but not to the extent Black women have faced. Additionally, it is astonishing that something like this can be so prevalent yet there is no documentation of the complications these women experience. How can we acknowledge and fix a structural problem when it is not documented? An important aspect is the intersection of classism and racism. Individuals who have more money are able to afford better doctors, prenatal care, and have the ability to request and afford additional tests to ensure the best health for both them and their child. 
 
|       I really enjoyed the section of this chapter that focused in on the lack of "bodies" within data science. To me, what this meant is that we often see data science as just numbers that tell a story. What we often fail to recognize are the individuals who are behind the numbers, writing the code, and implementing the models. Bodies are an essential part of data science, which means biases (sexism, classism, ageism, racism, etc.) are intertwined in algorithms because of our humanness. This recognition that data science has flaws is not something we should gravely condemn or get angry over, especially since many of these biases are ones that individuals subconsciously include in their code. Instead what we need is to have diverse teams at companies and institutions that collaborate with one another and offer different perspectives on possible outcomes of code before it is published for use. Once we observe an injustice in the field, we need to discuss it and formulate a plan to move forward. By not including individuals with different backgrounds (gender, ethnicity, sexuality, socioeconomic background, religion, etc.), both in observation and in conversation, we artificially create missing data. Circling back to the earlier topic of Black women experiencing complications during childbirth, hospitals should begin documenting every birth procedure (time, ethnicity of patient, complications, geographical location, etc.) and report these to a specialized group within the CDC or a similar government health agency. Then, a diverse team of data scientists should analyze the data to see if there are any trends or outliers to further examine. This would be a starting point to tackle this issue since it would allow us to visually see the trend of complications (which previously has been only anecdotal). 
 
 <p>&nbsp;</p>
 

Check out these resources to learn more:
 
 - 1.  [Joy Buolamwini: How I'm fighting bias in algorithms](https://www.ted.com/talks/joy_buolamwini_how_i_m_fighting_bias_in_algorithms?language=en)
 
 - 2.  [Tricia Wang: The human insights missing from big data](https://www.ted.com/talks/tricia_wang_the_human_insights_missing_from_big_data/reading-list?nolanguage=nya)
 
 - 3.  [Robin Hauser: Can we protect AI from our biases?](https://www.ted.com/talks/robin_hauser_can_we_protect_ai_from_our_biases)
 
 - 4.  [The Ada Lovelace Institute - Black Data Matters: How Missing Data Undermines Equitable Societies](https://www.youtube.com/watch?v=qYt-1pnH1UE)
 
 
 
 
 